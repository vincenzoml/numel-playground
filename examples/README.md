# Example Workflows

Compact JSON format â€” importable via the workflow generate/import UI.

## webcam-frontend-ml.json
**Nodes**: `start` â†’ `browser_source` (webcam) â†’ `end`

Shows client-side (browser-only) pose detection with zero backend involvement:
- Minimal workflow â€” just enough to instantiate the webcam overlay node
- No backend workflow execution needed for pose rendering
- After import: click **Start** on the webcam overlay to enable the camera, then click **ðŸ§  ML On** to start MediaPipe inference in the browser (WebAssembly, 20 fps)
- Skeleton is drawn directly on the overlay canvas; keypoints also forwarded to backend via WebSocket if available

Requires: browser with webcam + internet access for MediaPipe CDN on first load.

---

## webcam-pose-detection.json
**Nodes**: `start` â†’ `browser_source` (webcam) â†’ `loop_start` â†’ `event_listener` â†’ `transform` (extract frame) â†’ `pose_detector` â†’ `stream_display` â†’ `loop_end`

Shows:
- `browser_source_flow` with `device_type="webcam"`, `mode="event"`, `interval_ms=150`, explicit `source_id="cam_pose"`
- **Explicit `source_id` is required**: workflow and browser overlay must use the same ID so `stream_display_flow` can route overlay events back via `/ws/stream/cam_pose`
- `event_listener_flow` waiting on `sources.cam` (MULTI_INPUT dotted slot)
- `pose_detector_flow` receiving a bare-base64 JPEG frame, outputting `keypoints`
- `stream_display_flow` with `render_type="pose"` routing the skeleton back to the browser
- Transform handles both event-mode frames (`data` key, strips data-URL prefix) and stream-mode frames (`frame` key, bare base64)
- `loop_start_flow` / `loop_end_flow` for continuous capture; the `loop=true` edge is a visual hint

Requires: browser with webcam + `pip install mediapipe Pillow numpy` on the backend.

---

## timer-driven-agent.json
**Nodes**: `start` â†’ `backend/model/agent_options/agent_config` (wired) â†’ `timer_source` (10s) â†’ `loop_start` â†’ `event_listener` â†’ `transform` (build prompt) â†’ `agent_flow` â†’ `transform` (extract reply) â†’ `preview` â†’ `loop_end`

Shows:
- `timer_source_flow` with `interval_ms=10000`, `immediate=true` (fires on first execution)
- `event_listener_flow` collecting timer ticks
- Full agent subgraph: `backend_config` â†’ `model_config` â†’ `agent_options_config` â†’ `agent_config` â†’ `agent_flow`
- Periodic LLM analysis driven by a timer

Requires: Ollama + Mistral (or adjust `model_config` source/name).

---

## foreach-list-processor.json
**Nodes**: `start` â†’ `user_input` â†’ `transform` (split CSV) â†’ `for_each_start` â†’ `transform` (uppercase + index) â†’ `preview` â†’ `for_each_end` â†’ `end`

Shows:
- `user_input_flow` to collect a comma-separated string from the user
- `for_each_start_flow` iterating over a list; `current` output carries the current item
- Per-iteration `preview_flow` so each processed item is shown as the loop runs
- `loop=true` edge from `for_each_start` to `for_each_end` as UI loop hint

---

## webhook-json-handler.json
**Nodes**: `start` â†’ `webhook_source` (`/hook/events`) â†’ `loop_start` â†’ `event_listener` â†’ `transform` (process payload) â†’ `preview` (JSON) â†’ `loop_end`

Shows:
- `webhook_source_flow` listening on a custom HTTP endpoint (`/hook/events`)
- `event_listener_flow` blocking until an HTTP POST arrives
- Transform annotates the payload with a timestamp and extracts keys
- `preview_flow` with `hint="json"` for pretty JSON display

Test: `curl -X POST http://localhost:8000/hook/events -H "Content-Type: application/json" -d '{"msg":"hello"}'`

---

## microphone-audio-gate.json
**Nodes**: `start` â†’ `browser_source` (microphone, 0.5s chunks) â†’ `loop_start` â†’ `event_listener` â†’ `gate` (threshold=6, fires every 3s) â†’ `transform` (check gate state) â†’ `preview` (JSON) â†’ `loop_end`

Shows:
- `browser_source_flow` with `device_type="microphone"`, `mode="event"`
- `gate_flow` accumulating 6 chunks (= 3 seconds of audio) before firing
- `gate_flow` outputs: `accumulated` (list of chunks), `triggered` (bool), `count` (int)
- Transform differentiates accumulating vs batch-ready state
- Demonstrates batch-triggering pattern without agent â€” replace transform+preview with an agent for real transcription

Requires: browser microphone permission.
